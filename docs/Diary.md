## Задача: Дневник проектных решений и технических наблюдений
- **Статус**: В процессе
- **Описание**: Фиксировать ключевые технические решения, выявленные проблемы и выбранные подходы для бесшовной передачи контекста между разработчиками.

# Diary.md

## Дата: 2026-02-19
### Наблюдения
- Проект стартует с нуля, в репозитории отсутствуют playbook/roles/inventory.
- Архитектура должна учитывать изолированную сеть и работу через прокси.
- Кластерная топология задана: 3 control-plane, 3 worker, 3 dedicated MetalLB nodes.
- Есть строгие требования к идемпотентности, безопасности (firewalld/SELinux) и поддержке NFS persistent storage.

### Решения
- Зафиксирована базовая целевая архитектура и поэтапный план в `docs/Project.md`.
- Сформирован стартовый task backlog с приоритетами в `docs/Tasktracker.md`.
- Выбран подход "сначала сбор входных данных, затем реализация playbook".
- Вынесены открытые вопросы в `docs/qa.md` для формализации параметров среды.

### Проблемы
- Отсутствуют обязательные входные параметры (сети, версии, политика прокси/no_proxy, детали NFS, порты и security baseline).
- Не подтвержден стек Kubernetes (версия kubeadm/kubelet и container runtime).
- Не определена стратегия источников пакетов/образов для полностью изолированного контура.

## Дата: 2026-02-19 (сессия 2)
### Наблюдения
- Получены конкретные параметры VMware, сетевой схемы, версии Kubernetes, CNI, MetalLB, NFS и security baseline.
- Подтверждена целевая модель: `kubeadm + containerd + calico + metallb(l2) + nginx ingress + nfs`.
- Большинство входных данных закрыто, но остаются критичные неоднозначности по сети и прокси.

### Решения
- Зафиксированы параметры среды в `docs/Project.md` (раздел 12).
- Обновлен прогресс в `docs/Tasktracker.md` (T-002 = 80%).
- `docs/qa.md` переведен в формат "закрытые вопросы + блокеры + варианты закрытия".

### Проблемы
- Несоответствие `management_subnet_cidr` и фактической подсети узлов.
- Не подтверждена топология прокси (`127.0.0.1` локально/централизованно).
- Не заполнены `acceptance_criteria`, `performance_requirements`, `backup_snapshot_strategy`.

## Дата: 2026-02-19 (сессия 3)
### Наблюдения
- Подтверждена management-подсеть `10.255.106.0/26`.
- Подтверждена прокси-модель `local_on_each_node` и формат proxy URL со схемой.
- Зафиксирован label для выделенных MetalLB-нод без taints.

### Решения
- Актуализированы `docs/Project.md`, `docs/qa.md` и `docs/Tasktracker.md`.
- Список блокеров сужен до 4 незаполненных полей: NFS performance, NFS backup strategy, `require_check_diff_support`, `acceptance_criteria`.

### Проблемы
- Пользователь оставил пустыми целевые метрики NFS производительности.
- Пользователь оставил пустой backup/snapshot strategy.
- Пользователь не зафиксировал `require_check_diff_support` и `acceptance_criteria`.

## Дата: 2026-02-19 (сессия 4)
### Наблюдения
- Выбран вариант 3 для закрытия блокеров: production baseline + расширенные acceptance criteria.
- Сбор входных данных завершен, архитектурные блокеры сняты.

### Решения
- Зафиксированы NFS performance требования: `IOPS >= 2000`, `throughput >= 150 MB/s`, `latency <= 5 ms`.
- Зафиксирована стратегия backup: `daily snapshot`, `retention 14 days`.
- Зафиксирована политика `require_check_diff_support: yes`.
- Зафиксирован расширенный набор критериев приемки (deploy, идемпотентность, health, MetalLB/ingress, NFS PVC, failover control-plane).

### Проблемы
- Критичные блокеры для начала реализации отсутствуют.

## Дата: 2026-02-19 (сессия 5)
### Наблюдения
- Пользователь подтвердил переход к шагу реализации Ansible-каркаса.
- Входные данные согласованы и достаточны для генерации inventory/group_vars/playbooks/roles.

### Решения
- Этап реализации каркаса официально стартовал.
- В трекере задачи `T-003` и `T-004` переведены в `В процессе`.

### Проблемы
- На момент старта каркаса критичные блокеры отсутствуют.

## Дата: 2026-02-19 (сессия 6)
### Наблюдения
- Каркас Ansible-репозитория успешно создан в соответствии с архитектурой `Project.md`.
- Все базовые сущности (inventory, group_vars, playbooks, roles, ansible.cfg, requirements.yml) присутствуют.
- Локальная проверка `ansible-playbook --syntax-check` не выполнена из-за отсутствия `ansible-playbook` в окружении.

### Решения
- Этапы `T-003` и `T-004` закрыты как завершенные.
- В ролях добавлены базовые `assert`-проверки входных переменных и безопасные skeleton-задачи (`debug` с `changed_when: false`).
- Следующий этап: наполнение ролей рабочей логикой установки и конфигурации.

### Проблемы
- В текущем окружении отсутствует `ansible-playbook`, поэтому syntax-check нужно выполнить после установки Ansible.

## Дата: 2026-02-19 (сессия 7)
### Наблюдения
- Пользователь подтвердил переход к следующему этапу: реализация рабочей логики ролей.
- Приоритет реализации: `base_os -> proxy -> container_runtime -> kubernetes_core -> networking -> metallb -> storage_nfs -> security_hardening -> validation`.

### Решения
- Этап реализации ролей официально стартован.
- Задачи `T-005`...`T-012` переведены в статус `В процессе`.

### Проблемы
- Для финальной проверки потребуется среда с установленным `ansible-playbook`.

## Дата: 2026-02-19 (сессия 8)
### Наблюдения
- Реализация ролей выполнена в полном согласованном порядке.
- Логика плейбуков переведена с skeleton-задач на реальные операции развертывания.
- Проверка `ansible-playbook --syntax-check` по-прежнему недоступна из-за отсутствия Ansible в окружении разработки.

### Решения
- Реализованы роли `base_os`, `proxy`, `container_runtime`, `kubernetes_core`, `networking`, `metallb`, `storage_nfs`, `security_hardening`, `validation`.
- Обновлен `bootstrap.yml`: `kubernetes_core` применяется ко всей группе `k8s_cluster` для корректного join всех нод.
- Расширен `group_vars/all.yml` для runtime и `no_proxy` диапазонов кластера.

### Проблемы
- Фактическая проверка на стенде (деплой, идемпотентность, post-check) отложена до установки `ansible-playbook`.

## Дата: 2026-02-19 (сессия 9)
### Наблюдения
- Появились новые требования: hostname узлов должен устанавливаться по именам из inventory.
- Деплой должен поддерживать два режима сети: с proxy и без proxy.

### Решения
- Стартована доработка `T-017` для hostname-синхронизации и параметризации proxy.
- Сначала обновлена документация, затем начинается изменение ролей/переменных.

### Проблемы
- После изменения логики прокси потребуется повторная стендовая валидация в обоих режимах (`proxy_enabled=true/false`).

## Дата: 2026-02-19 (сессия 10)
### Наблюдения
- Требование по hostname из inventory реализовано на уровне `base_os`.
- Прокси-настройка теперь управляется параметром `proxy_enabled`.

### Решения
- Добавлен параметр `proxy_enabled` в `group_vars/all.yml`.
- Роль `proxy` сделана условной в `playbooks/bootstrap.yml`.
- Команды `kubectl apply` в ролях `networking`, `metallb`, `storage_nfs` переведены на условный `proxy_environment`.
- Добавлена генерация `/etc/hosts` из inventory для консистентного name-resolution внутри кластера.

### Проблемы
- Нужна последующая проверка на control host в двух профилях: `proxy_enabled=true` и `proxy_enabled=false`.

## Дата: 2026-02-19 (сессия 11)
### Наблюдения
- Подтверждено требование: проверки будут выполняться позже на control host.
- Необходим отдельный runbook с командами запуска для двух сетевых профилей.

### Решения
- Стартована задача `T-018` по подготовке эксплуатационного runbook.

### Проблемы
- До публикации runbook отсутствует единый стандартизованный сценарий запуска/проверок для control host.

## Дата: 2026-02-19 (сессия 12)
### Наблюдения
- Runbook для control host подготовлен как отдельный документ в `docs`.
- В runbook включены оба сетевых режима (`proxy_enabled=true/false`) и блок проверок hostname по inventory.

### Решения
- Завершена задача `T-018` по эксплуатационной документации.
- В качестве единого operational entrypoint принят `docs/runbook.md`.

### Проблемы
- Практический прогон шагов runbook будет выполнен позже на control host (по плану пользователя).

## Дата: 2026-02-19 (сессия 13)
### Наблюдения
- Добавлено новое требование: сценарий полной переустановки кластера с уничтожением всех данных (`cluster_and_nfs`).
- Требование относится к деструктивным операциям и требует guardrail-механизмов.

### Решения
- Добавлен отдельный playbook `playbooks/reinstall_cluster_and_nfs.yml`.
- В playbook реализованы обязательные подтверждения через переменные:
  - `reinstall_scope=cluster_and_nfs`
  - `reinstall_confirm_token=DESTROY_CLUSTER_AND_NFS_DATA`
- В `docs/runbook.md` добавлен раздел запуска деструктивного сценария.

### Проблемы
- Стендовая проверка деструктивного сценария отложена до выполнения на control host.

## Дата: 2026-02-19 (сессия 14)
### Наблюдения
- Добавлено требование: при развертывании NFS нужна опция выбора диска для разметки и монтирования.
- Требование должно работать как опциональный сценарий, без влияния на существующий путь с готовой файловой системой.

### Решения
- В роль `storage_nfs` добавлены параметры data-диска и условные задачи:
  - `parted` (разметка),
  - `filesystem` (создание ФС),
  - `mount` (монтирование в `nfs_export_path`).
- В `group_vars/nfs.yml` добавлены переменные для настройки этого поведения.
- В runbook добавлен раздел с примером включения опции.

### Проблемы
- Перед использованием на production требуется валидация на стенде с тестовым диском.

## Дата: 2026-02-19 (сессия 15)
### Наблюдения
- Запрошено усиление безопасности: запрет выбора системного диска в сценарии NFS data-диска.

### Решения
- Стартована задача `T-021` на реализацию guardrail с возможностью явного override.

### Проблемы
- Без guardrail остается риск ошибочного форматирования системного диска.

## Дата: 2026-02-19 (сессия 16)
### Наблюдения
- Guardrail для NFS data-диска реализован в роли `storage_nfs`.
- По умолчанию системный диск блокируется для выбора как `storage_nfs_data_disk_device`.

### Решения
- Добавлены проверки критических mount-sources (`/`, `/boot`, `/boot/efi`, `/var`) и их parent-дисков.
- Добавлен explicit override-параметр `storage_nfs_data_disk_allow_system_disk` (по умолчанию `false`).
- Обновлен runbook с описанием guardrail и условиями обхода.

### Проблемы
- Для production нужен обязательный dry-run/стендовый прогон перед использованием override-флага.

## Дата: 2026-02-19 (сессия 17)
### Наблюдения
- Подтверждено архитектурное ограничение: нет доступа к изменению сетевых настроек в `vCenter`.
- Для публикации сервисов в `MetalLB L2` требуется операционный сценарий без зависимости от vCenter-изменений.

### Решения
- В `Project.md` зафиксирована модель публикации: `Service type=LoadBalancer` + VIP из пула MetalLB.
- В `runbook.md` добавлен отдельный checklist для `MetalLB L2` без доступа к `vCenter`.
- Добавлены команды для фиксации статического VIP ingress (`metallb.io/loadBalancerIPs`) и проверки доступности по `80/443`.

### Проблемы
- Внешние предпосылки (IPAM/DHCP reservation, маршрутизация, firewall, DNS) зависят от сетевой команды и должны быть выполнены до приемки.

## Дата: 2026-02-19 (сессия 18)
### Наблюдения
- Требуется автоматизировать проверку публикации ingress через VIP в рамках роли `validation`.
- Текущая валидация проверяет readiness нод, MetalLB controller и NFS StorageClass, но не проверяет ingress EXTERNAL-IP.

### Решения
- Стартована задача `T-023` на добавление post-check для `Service type=LoadBalancer` и выделенного VIP ingress.
- В `roles/validation/tasks/main.yml` добавлен блок проверок ingress-сервиса:
  - тип сервиса `LoadBalancer`,
  - наличие внешнего адреса (`ip` или `hostname`),
  - опциональная сверка с `validation_ingress_expected_vip`.
- В `group_vars/all.yml` зафиксирован ожидаемый VIP `10.255.106.21`.
- В `runbook.md` добавлена инструкция по включению/отключению автоматической проверки.

### Проблемы
- Значение ожидаемого ingress VIP должно быть параметризуемым, чтобы не ломать сценарии без фиксированного VIP.
- Стендовая проверка `playbooks/validate.yml` отложена до запуска на control host.
