# ## Задача: Роль kubernetes_core
# - **Статус**: В процессе
# - **Описание**: Управление установкой и bootstrap Kubernetes.
- name: Validate Kubernetes core variables
  ansible.builtin.assert:
    that:
      - kubernetes_version is defined
      - kubernetes_packages is iterable
      - kubernetes_packages | length > 0
      - kubeadm_config_api_version is defined
      - kubeadm_config_api_version | length > 0
      - control_plane_endpoint is defined
      - pod_subnet_cidr is defined
      - service_subnet_cidr is defined
      - groups['control_plane'] | length > 0
    fail_msg: "Kubernetes core variables are incomplete"

- name: Resolve Kubernetes package list for install
  ansible.builtin.set_fact:
    kubernetes_packages_resolved: >-
      {{
        (
          kubernetes_packages
          | map('regex_replace', '$', '-' ~ kubernetes_packages_version_override)
          | list
        )
        if (kubernetes_packages_version_override | default('') | length > 0)
        else kubernetes_packages
      }}

- name: Define node role flags
  ansible.builtin.set_fact:
    primary_control_plane: "{{ groups['control_plane'][0] }}"
    is_primary_control_plane: "{{ inventory_hostname == groups['control_plane'][0] }}"
    is_control_plane_node: "{{ inventory_hostname in groups['control_plane'] }}"
    is_worker_like_node: "{{ inventory_hostname in (groups['workers'] + groups['metallb']) }}"
    kubernetes_runtime_service_name: "{{ 'containerd' if (container_runtime_name | default('containerd')) == 'containerd' else 'crio' }}"
    kubernetes_runtime_socket_path: "{{ '/run/containerd/containerd.sock' if (container_runtime_name | default('containerd')) == 'containerd' else '/var/run/crio/crio.sock' }}"

- name: Configure Kubernetes repository
  ansible.builtin.template:
    src: kubernetes.repo.j2
    dest: /etc/yum.repos.d/kubernetes.repo
    mode: "0644"

- name: Refresh Kubernetes repo metadata with retries
  ansible.builtin.command: dnf -q makecache --refresh --disablerepo='*' --enablerepo=kubernetes
  register: kubernetes_repo_makecache
  changed_when: false
  retries: "{{ kubernetes_repo_validate_retries | int }}"
  delay: "{{ kubernetes_repo_validate_delay | int }}"
  until: kubernetes_repo_makecache.rc == 0
  when: kubernetes_repo_validate_before_install | bool
  environment: "{{ proxy_environment | default({}) }}"

- name: Install Kubernetes packages
  ansible.builtin.dnf:
    name: "{{ kubernetes_packages_resolved }}"
    state: present
  register: kubernetes_packages_install_result
  retries: "{{ kubernetes_package_install_retries | int }}"
  delay: "{{ kubernetes_package_install_delay | int }}"
  until: kubernetes_packages_install_result is succeeded
  environment: "{{ proxy_environment | default({}) }}"

- name: Ensure kubelet is enabled
  ansible.builtin.service:
    name: kubelet
    enabled: true
    state: started

- name: Render kubeadm config on primary control-plane
  ansible.builtin.template:
    src: kubeadm-config.yaml.j2
    dest: "{{ kubeadm_config_path }}"
    mode: "0644"
  when: is_primary_control_plane | bool

- name: Ensure runtime service is running before kubeadm init
  ansible.builtin.service:
    name: "{{ kubernetes_runtime_service_name }}"
    state: started
    enabled: true
  when: is_primary_control_plane | bool

- name: Wait for runtime socket before kubeadm init
  ansible.builtin.wait_for:
    path: "{{ kubernetes_runtime_socket_path }}"
    timeout: 60
  when: is_primary_control_plane | bool

- name: Check swap devices before kubeadm init
  ansible.builtin.command: swapon --noheadings --raw
  register: kubernetes_swap_check
  changed_when: false
  when: is_primary_control_plane | bool

- name: Ensure swap is disabled before kubeadm init
  ansible.builtin.assert:
    that:
      - (kubernetes_swap_check.stdout | default('') | trim) == ''
    fail_msg: >-
      Swap must be disabled before kubeadm init. Current swap entries:
      {{ kubernetes_swap_check.stdout | default('none') }}
  when: is_primary_control_plane | bool

- name: Ensure control-plane endpoint listener is reachable before kubeadm init
  ansible.builtin.wait_for:
    host: "{{ control_plane_endpoint }}"
    port: "{{ control_plane_endpoint_port | int }}"
    timeout: "{{ kubeadm_init_endpoint_check_timeout | int }}"
  register: kubernetes_control_plane_endpoint_check
  retries: "{{ kubeadm_init_endpoint_check_retries | int }}"
  delay: "{{ kubeadm_init_endpoint_check_delay | int }}"
  until: kubernetes_control_plane_endpoint_check is succeeded
  when: is_primary_control_plane | bool

- name: Check existing cluster readiness before kubeadm init
  ansible.builtin.command: kubectl --kubeconfig /etc/kubernetes/admin.conf get --raw=/readyz
  register: kubernetes_existing_cluster_readyz
  changed_when: false
  failed_when: false
  when: is_primary_control_plane | bool

- name: Check stale kubeadm manifests before kubeadm init
  ansible.builtin.stat:
    path: /etc/kubernetes/manifests/kube-apiserver.yaml
  register: kubernetes_kubeadm_apiserver_manifest
  when:
    - is_primary_control_plane | bool
    - (kubernetes_existing_cluster_readyz.rc | default(1)) != 0

- name: Check stale etcd data directory before kubeadm init
  ansible.builtin.find:
    paths: /var/lib/etcd
    recurse: false
    file_type: any
  register: kubernetes_kubeadm_etcd_dir_entries
  failed_when: false
  changed_when: false
  when:
    - is_primary_control_plane | bool
    - (kubernetes_existing_cluster_readyz.rc | default(1)) != 0

- name: Detect stale kubeadm state before kubeadm init
  ansible.builtin.set_fact:
    kubernetes_kubeadm_stale_state: >-
      {{
        (kubernetes_kubeadm_apiserver_manifest.stat.exists | default(false))
        or ((kubernetes_kubeadm_etcd_dir_entries.matched | default(0) | int) > 0)
      }}
  when:
    - is_primary_control_plane | bool
    - (kubernetes_existing_cluster_readyz.rc | default(1)) != 0

- name: Auto-reset stale kubeadm state before kubeadm init
  block:
    - name: Stop kubelet before kubeadm reset
      ansible.builtin.service:
        name: kubelet
        state: stopped

    - name: Run kubeadm reset for stale init state
      ansible.builtin.command: kubeadm reset -f
      register: kubernetes_kubeadm_reset
      changed_when: kubernetes_kubeadm_reset.rc == 0

    - name: Remove stale static pod manifests after reset
      ansible.builtin.file:
        path: "{{ item }}"
        state: absent
      loop:
        - /etc/kubernetes/manifests/kube-apiserver.yaml
        - /etc/kubernetes/manifests/kube-controller-manager.yaml
        - /etc/kubernetes/manifests/kube-scheduler.yaml
        - /etc/kubernetes/manifests/etcd.yaml

    - name: Remove stale etcd data directory after reset
      ansible.builtin.file:
        path: /var/lib/etcd
        state: absent
  when:
    - is_primary_control_plane | bool
    - (kubernetes_existing_cluster_readyz.rc | default(1)) != 0
    - kubernetes_kubeadm_stale_state | default(false)
    - kubeadm_init_auto_reset_on_stale_state | bool

- name: Fail when stale kubeadm state is found and auto-reset is disabled
  ansible.builtin.fail:
    msg: >-
      Stale kubeadm state detected on {{ inventory_hostname }}:
      kube-apiserver manifest exists={{ kubernetes_kubeadm_apiserver_manifest.stat.exists | default(false) }},
      /var/lib/etcd entries={{ kubernetes_kubeadm_etcd_dir_entries.matched | default(0) }}.
      The cluster API is not healthy (`/readyz` check failed), so repeated `kubeadm init` will fail preflight.
      Run destructive reinstall playbook or set `kubeadm_init_auto_reset_on_stale_state=true`.
  when:
    - is_primary_control_plane | bool
    - (kubernetes_existing_cluster_readyz.rc | default(1)) != 0
    - kubernetes_kubeadm_stale_state | default(false)
    - not (kubeadm_init_auto_reset_on_stale_state | bool)

- name: Ensure kubelet is started after stale-state auto-reset
  ansible.builtin.service:
    name: kubelet
    state: started
    enabled: true
  when:
    - is_primary_control_plane | bool
    - (kubernetes_existing_cluster_readyz.rc | default(1)) != 0
    - kubernetes_kubeadm_stale_state | default(false)
    - kubeadm_init_auto_reset_on_stale_state | bool

- name: Initialize Kubernetes cluster on primary control-plane
  block:
    - name: Run kubeadm init
      ansible.builtin.command: >-
        kubeadm init
        --config {{ kubeadm_config_path }}
        --upload-certs
        {{ '--allow-experimental-api' if (kubeadm_init_allow_experimental_api | bool) else '' }}
        {{ ('--v=' ~ (kubeadm_init_verbosity | int | string)) if (kubeadm_init_verbose | bool) else '' }}
      when:
        - (kubernetes_existing_cluster_readyz.rc | default(1)) != 0
  rescue:
    - name: Collect kubelet service state
      ansible.builtin.command: systemctl is-active kubelet
      register: kubernetes_kubelet_state
      changed_when: false
      failed_when: false

    - name: Collect runtime service state
      ansible.builtin.command: "systemctl is-active {{ kubernetes_runtime_service_name }}"
      register: kubernetes_runtime_state
      changed_when: false
      failed_when: false

    - name: Collect kubelet logs tail
      ansible.builtin.command: journalctl -u kubelet -n 300 --no-pager
      register: kubernetes_kubelet_logs
      changed_when: false
      failed_when: false

    - name: Collect CRI containers summary when crictl exists
      ansible.builtin.shell: |
        if command -v crictl >/dev/null 2>&1; then
          crictl --runtime-endpoint {{ kubeadm_cri_socket }} ps -a | grep -E 'kube|etcd' || true
        else
          echo "crictl not installed"
        fi
      args:
        executable: /bin/bash
      register: kubernetes_cri_ps
      changed_when: false
      failed_when: false

    - name: Probe control-plane backend reachability for VIP diagnostics
      ansible.builtin.wait_for:
        host: "{{ hostvars[item].ansible_host | default(item) }}"
        port: 6443
        timeout: 2
      loop: "{{ groups['control_plane'] }}"
      register: kubernetes_control_plane_backend_checks
      changed_when: false
      failed_when: false

    - name: Fail explicitly when VIP endpoint is reachable but all API backends are down
      ansible.builtin.fail:
        msg: >-
          controlPlaneEndpoint {{ control_plane_endpoint }}:{{ control_plane_endpoint_port | int }}
          is reachable, but no control-plane backend responds on port 6443.
          This usually means HAProxy/keepalived VIP path is up while kube-apiserver backends are unavailable.
          Reachable backends: {{
            (
              kubernetes_control_plane_backend_checks.results
              | selectattr('failed', 'equalto', false)
              | map(attribute='item')
              | list
            ) | join(', ')
            | default('none', true)
          }}.
      when:
        - (control_plane_endpoint_port | int) != 6443
        - kubernetes_control_plane_endpoint_check is defined
        - kubernetes_control_plane_endpoint_check is succeeded
        - >
          (
            kubernetes_control_plane_backend_checks.results
            | selectattr('failed', 'equalto', false)
            | list
            | length
          ) == 0

    - name: Fail with kubeadm init diagnostics
      ansible.builtin.fail:
        msg: |
          kubeadm init failed on {{ inventory_hostname }}.
          kubeadm stderr:
          {{ ansible_failed_result.stderr | default('') }}

          controlPlaneEndpoint check: {{ control_plane_endpoint }}:{{ control_plane_endpoint_port | int }}
          pre-init readyz rc: {{ kubernetes_existing_cluster_readyz.rc | default('n/a') }}

          kubelet state: {{ kubernetes_kubelet_state.stdout | default('unknown') }}
          {{ kubernetes_runtime_service_name }} state: {{ kubernetes_runtime_state.stdout | default('unknown') }}

          CRI summary:
          {{ kubernetes_cri_ps.stdout | default('') }}

          kubelet logs (tail 120):
          {{ kubernetes_kubelet_logs.stdout | default('') }}
  when: is_primary_control_plane | bool

- name: Ensure kube config exists for root
  ansible.builtin.file:
    path: /root/.kube
    state: directory
    mode: "0700"
  when: is_primary_control_plane | bool

- name: Copy admin kubeconfig to root
  ansible.builtin.copy:
    src: /etc/kubernetes/admin.conf
    dest: /root/.kube/config
    remote_src: true
    mode: "0600"
  when: is_primary_control_plane | bool

- name: Ensure kube config exists for ansible user
  ansible.builtin.file:
    path: "/home/{{ kubernetes_admin_user }}/.kube"
    state: directory
    mode: "0700"
    owner: "{{ kubernetes_admin_user }}"
    group: "{{ kubernetes_admin_user }}"
  when:
    - is_primary_control_plane | bool
    - kubernetes_admin_user != 'root'

- name: Copy admin kubeconfig for ansible user
  ansible.builtin.copy:
    src: /etc/kubernetes/admin.conf
    dest: "/home/{{ kubernetes_admin_user }}/.kube/config"
    remote_src: true
    mode: "0600"
    owner: "{{ kubernetes_admin_user }}"
    group: "{{ kubernetes_admin_user }}"
  when:
    - is_primary_control_plane | bool
    - kubernetes_admin_user != 'root'

- name: Generate worker join command
  ansible.builtin.command: kubeadm token create --ttl 2h --print-join-command
  register: kubeadm_worker_join_command
  changed_when: false
  when: is_primary_control_plane | bool

- name: Upload control-plane certificates and capture key
  ansible.builtin.command: kubeadm init phase upload-certs --upload-certs
  register: kubeadm_upload_certs
  changed_when: false
  when: is_primary_control_plane | bool

- name: Save join commands on primary host facts
  ansible.builtin.set_fact:
    kubeadm_certificate_key: >-
      {{ kubeadm_upload_certs.stdout_lines | select('match', '^[a-f0-9]{64}$') | list | last | default('') }}
    kubeadm_join_worker_cmd: "{{ kubeadm_worker_join_command.stdout }}"
    kubeadm_join_control_plane_cmd: >-
      {{ kubeadm_worker_join_command.stdout }}
      --control-plane
      --certificate-key {{ kubeadm_upload_certs.stdout_lines | select('match', '^[a-f0-9]{64}$') | list | last | default('') }}
    cacheable: true
  when: is_primary_control_plane | bool

- name: Ensure worker join command is available
  ansible.builtin.assert:
    that:
      - hostvars[primary_control_plane].kubeadm_join_worker_cmd is defined
      - hostvars[primary_control_plane].kubeadm_join_worker_cmd | length > 0
    fail_msg: "Join command is not available from primary control-plane"
  when: not (is_primary_control_plane | bool)

- name: Define join endpoint candidates for non-primary nodes
  ansible.builtin.set_fact:
    kubeadm_join_endpoint_vip: "{{ control_plane_endpoint }}:{{ control_plane_endpoint_port | int }}"
    kubeadm_join_endpoint_fallback: "{{ hostvars[primary_control_plane].ansible_host }}:{{ kubeadm_join_fallback_port | int }}"
  when: not (is_primary_control_plane | bool)

- name: Probe controlPlaneEndpoint VIP before kubeadm join
  ansible.builtin.wait_for:
    host: "{{ control_plane_endpoint }}"
    port: "{{ control_plane_endpoint_port | int }}"
    timeout: "{{ kubeadm_join_endpoint_check_timeout | int }}"
  register: kubeadm_join_vip_wait
  until: kubeadm_join_vip_wait is succeeded
  retries: "{{ kubeadm_join_endpoint_check_retries | int }}"
  delay: "{{ kubeadm_join_endpoint_check_delay | int }}"
  ignore_errors: "{{ kubeadm_join_endpoint_fallback_enabled | bool }}"
  when:
    - not (is_primary_control_plane | bool)
    - not (kubeadm_join_force_primary_endpoint | bool)

- name: Select endpoint for kubeadm join
  ansible.builtin.set_fact:
    kubeadm_join_selected_endpoint: >-
      {{
        kubeadm_join_endpoint_fallback
        if (kubeadm_join_force_primary_endpoint | bool)
        else
          (
            kubeadm_join_endpoint_vip
            if (kubeadm_join_vip_wait is succeeded)
            else kubeadm_join_endpoint_fallback
          )
      }}
    kubeadm_join_selected_host: >-
      {{
        hostvars[primary_control_plane].ansible_host
        if (kubeadm_join_force_primary_endpoint | bool)
        else
          (
            control_plane_endpoint
            if (kubeadm_join_vip_wait is succeeded)
            else hostvars[primary_control_plane].ansible_host
          )
      }}
    kubeadm_join_selected_port: >-
      {{
        (kubeadm_join_fallback_port | int)
        if (kubeadm_join_force_primary_endpoint | bool)
        else
          (
            (control_plane_endpoint_port | int)
            if (kubeadm_join_vip_wait is succeeded)
            else (kubeadm_join_fallback_port | int)
          )
      }}
  when: not (is_primary_control_plane | bool)

- name: Wait for selected kubeadm join endpoint to become reachable
  block:
    - name: Probe selected kubeadm join endpoint
      ansible.builtin.wait_for:
        host: "{{ kubeadm_join_selected_host }}"
        port: "{{ kubeadm_join_selected_port | int }}"
        timeout: "{{ kubeadm_join_endpoint_check_timeout | int }}"
      register: kubeadm_join_selected_endpoint_wait
      until: kubeadm_join_selected_endpoint_wait is succeeded
      retries: "{{ kubeadm_join_endpoint_check_retries | int }}"
      delay: "{{ kubeadm_join_endpoint_check_delay | int }}"
  rescue:
    - name: Collect route diagnostics to selected join endpoint
      ansible.builtin.command: "ip route get {{ kubeadm_join_selected_host }}"
      register: kubeadm_join_route_diag
      changed_when: false
      failed_when: false

    - name: Collect TCP probe diagnostics to selected join endpoint
      ansible.builtin.shell: >-
        timeout {{ kubeadm_join_endpoint_check_timeout | int }}
        bash -c '</dev/tcp/{{ kubeadm_join_selected_host }}/{{ kubeadm_join_selected_port | int }}'
      register: kubeadm_join_tcp_diag
      changed_when: false
      failed_when: false

    - name: Collect readyz diagnostics to selected join endpoint
      ansible.builtin.command: >-
        curl -k --connect-timeout {{ kubeadm_join_endpoint_check_timeout | int }}
        https://{{ kubeadm_join_selected_host }}:{{ kubeadm_join_selected_port | int }}/readyz
      register: kubeadm_join_readyz_diag
      changed_when: false
      failed_when: false

    - name: Fail with aggregated join endpoint diagnostics
      ansible.builtin.fail:
        msg: |
          Selected kubeadm join endpoint is unreachable from node {{ inventory_hostname }}.
          Selected endpoint: {{ kubeadm_join_selected_endpoint }}
          Route probe rc={{ kubeadm_join_route_diag.rc | default('n/a') }}:
          {{ (kubeadm_join_route_diag.stdout | default('') | trim) if (kubeadm_join_route_diag.stdout | default('') | trim | length > 0) else (kubeadm_join_route_diag.stderr | default('') | trim) }}
          TCP probe rc={{ kubeadm_join_tcp_diag.rc | default('n/a') }}:
          {{ (kubeadm_join_tcp_diag.stdout | default('') | trim) if (kubeadm_join_tcp_diag.stdout | default('') | trim | length > 0) else (kubeadm_join_tcp_diag.stderr | default('') | trim) }}
          readyz probe rc={{ kubeadm_join_readyz_diag.rc | default('n/a') }}:
          {{ (kubeadm_join_readyz_diag.stdout | default('') | trim) if (kubeadm_join_readyz_diag.stdout | default('') | trim | length > 0) else (kubeadm_join_readyz_diag.stderr | default('') | trim) }}
  when: not (is_primary_control_plane | bool)

- name: Join secondary control-plane nodes
  ansible.builtin.command: >-
    {{ hostvars[primary_control_plane].kubeadm_join_control_plane_cmd
    | regex_replace('^kubeadm join\\s+\\S+', 'kubeadm join ' ~ kubeadm_join_selected_endpoint) }}
    --apiserver-advertise-address {{ ansible_host }}
  args:
    creates: /etc/kubernetes/kubelet.conf
  register: kubeadm_join_control_plane_result
  until: kubeadm_join_control_plane_result.rc == 0
  retries: "{{ kubeadm_join_retries | int }}"
  delay: "{{ kubeadm_join_delay | int }}"
  throttle: 1
  when:
    - is_control_plane_node | bool
    - not (is_primary_control_plane | bool)

- name: Join worker and metallb nodes
  ansible.builtin.command: >-
    {{ hostvars[primary_control_plane].kubeadm_join_worker_cmd
    | regex_replace('^kubeadm join\\s+\\S+', 'kubeadm join ' ~ kubeadm_join_selected_endpoint) }}
  args:
    creates: /etc/kubernetes/kubelet.conf
  register: kubeadm_join_worker_result
  until: kubeadm_join_worker_result.rc == 0
  retries: "{{ kubeadm_join_retries | int }}"
  delay: "{{ kubeadm_join_delay | int }}"
  throttle: 1
  when: is_worker_like_node | bool

- name: Resolve architecture for control-plane CLI tools
  ansible.builtin.set_fact:
    kubernetes_cli_tools_arch: "{{ kubernetes_cli_tools_arch_map.get(ansible_architecture, 'amd64') }}"
  when:
    - is_control_plane_node | bool
    - kubernetes_install_helm_tools_on_control_plane | bool

- name: Ensure temporary directory for CLI tools exists
  ansible.builtin.file:
    path: "{{ kubernetes_cli_tools_tmp_dir }}"
    state: directory
    mode: "0755"
  when:
    - is_control_plane_node | bool
    - kubernetes_install_helm_tools_on_control_plane | bool

- name: Download Helm archive
  ansible.builtin.get_url:
    url: "https://get.helm.sh/helm-{{ kubernetes_helm_version }}-linux-{{ kubernetes_cli_tools_arch }}.tar.gz"
    dest: "{{ kubernetes_cli_tools_tmp_dir }}/helm-{{ kubernetes_helm_version }}-linux-{{ kubernetes_cli_tools_arch }}.tar.gz"
    mode: "0644"
  environment: "{{ proxy_environment | default({}) }}"
  when:
    - is_control_plane_node | bool
    - kubernetes_install_helm_tools_on_control_plane | bool

- name: Extract Helm archive
  ansible.builtin.unarchive:
    src: "{{ kubernetes_cli_tools_tmp_dir }}/helm-{{ kubernetes_helm_version }}-linux-{{ kubernetes_cli_tools_arch }}.tar.gz"
    dest: "{{ kubernetes_cli_tools_tmp_dir }}"
    remote_src: true
  when:
    - is_control_plane_node | bool
    - kubernetes_install_helm_tools_on_control_plane | bool

- name: Install Helm binary
  ansible.builtin.copy:
    src: "{{ kubernetes_cli_tools_tmp_dir }}/linux-{{ kubernetes_cli_tools_arch }}/helm"
    dest: /usr/local/bin/helm
    remote_src: true
    mode: "0755"
  when:
    - is_control_plane_node | bool
    - kubernetes_install_helm_tools_on_control_plane | bool

- name: Download Helmfile archive
  ansible.builtin.get_url:
    url: "https://github.com/helmfile/helmfile/releases/download/{{ kubernetes_helmfile_version }}/helmfile_{{ kubernetes_helmfile_version_no_v }}_linux_{{ kubernetes_cli_tools_arch }}.tar.gz"
    dest: "{{ kubernetes_cli_tools_tmp_dir }}/helmfile_{{ kubernetes_helmfile_version_no_v }}_linux_{{ kubernetes_cli_tools_arch }}.tar.gz"
    mode: "0644"
  environment: "{{ proxy_environment | default({}) }}"
  when:
    - is_control_plane_node | bool
    - kubernetes_install_helm_tools_on_control_plane | bool

- name: Ensure Helmfile extraction directory exists
  ansible.builtin.file:
    path: "{{ kubernetes_cli_tools_tmp_dir }}/helmfile"
    state: directory
    mode: "0755"
  when:
    - is_control_plane_node | bool
    - kubernetes_install_helm_tools_on_control_plane | bool

- name: Extract Helmfile archive
  ansible.builtin.unarchive:
    src: "{{ kubernetes_cli_tools_tmp_dir }}/helmfile_{{ kubernetes_helmfile_version_no_v }}_linux_{{ kubernetes_cli_tools_arch }}.tar.gz"
    dest: "{{ kubernetes_cli_tools_tmp_dir }}/helmfile"
    remote_src: true
  when:
    - is_control_plane_node | bool
    - kubernetes_install_helm_tools_on_control_plane | bool

- name: Install Helmfile binary
  ansible.builtin.copy:
    src: "{{ kubernetes_cli_tools_tmp_dir }}/helmfile/helmfile"
    dest: /usr/local/bin/helmfile
    remote_src: true
    mode: "0755"
  when:
    - is_control_plane_node | bool
    - kubernetes_install_helm_tools_on_control_plane | bool
